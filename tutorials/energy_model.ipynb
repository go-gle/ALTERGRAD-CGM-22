{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec62bbc-7f2f-4fa3-8cd4-d7c4fcc3a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 00:06:01.692853: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fe81d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14629b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37da032-e817-4841-a30b-741c4b197933",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# X_train = X_train[y_train == 0]\n",
    "X_train = torch.Tensor(X_train).unsqueeze(1) / 256\n",
    "X_test = torch.Tensor(X_test).unsqueeze(1) / 256\n",
    "\n",
    "train_loader = DataLoader(X_train, batch_size=64, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(X_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f8ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_features=32, out_dim=1, **kwargs):\n",
    "        super().__init__()\n",
    "        # We increase the hidden dimension over layers. Here pre-calculated for simplicity.\n",
    "        c_hid1 = hidden_features//2\n",
    "        c_hid2 = hidden_features\n",
    "        c_hid3 = hidden_features*2\n",
    "        \n",
    "        # Series of convolutions and Swish activation functions\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "                nn.Conv2d(1, c_hid1, kernel_size=5, stride=2, padding=4), # [16x16] - Larger padding to get 32x32 image\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid1, c_hid2, kernel_size=3, stride=2, padding=1), #  [8x8]\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid2, c_hid3, kernel_size=3, stride=2, padding=1), # [4x4]\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid3, c_hid3, kernel_size=3, stride=2, padding=1), # [2x2]\n",
    "                Swish(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(c_hid3*4, c_hid3),\n",
    "                Swish(),\n",
    "                nn.Linear(c_hid3, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x).squeeze(dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3417e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "\n",
    "    def __init__(self, model, img_shape, sample_size, max_len=8192):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model - Neural network to use for modeling E_theta\n",
    "            img_shape - Shape of the images to model\n",
    "            sample_size - Batch size of the samples\n",
    "            max_len - Maximum number of data points to keep in the buffer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.img_shape = img_shape\n",
    "        self.sample_size = sample_size\n",
    "        self.max_len = max_len\n",
    "        self.examples = [(torch.rand((1,)+img_shape)*2-1) for _ in range(self.sample_size)]\n",
    "\n",
    "    def sample_new_exmps(self, steps=60, step_size=10):\n",
    "        \"\"\"\n",
    "        Function for getting a new batch of \"fake\" images.\n",
    "        Inputs:\n",
    "            steps - Number of iterations in the MCMC algorithm\n",
    "            step_size - Learning rate nu in the algorithm above\n",
    "        \"\"\"\n",
    "        # Choose 95% of the batch from the buffer, 5% generate from scratch\n",
    "        n_new = np.random.binomial(self.sample_size, 0.05)\n",
    "        rand_imgs = torch.rand((n_new,) + self.img_shape) * 2 - 1\n",
    "        old_imgs = torch.cat(random.choices(self.examples, k=self.sample_size-n_new), dim=0)\n",
    "        inp_imgs = torch.cat([rand_imgs, old_imgs], dim=0).detach().to(device)\n",
    "\n",
    "        # Perform MCMC sampling\n",
    "        inp_imgs = Sampler.generate_samples(self.model, inp_imgs, steps=steps, step_size=step_size)\n",
    "\n",
    "        # Add new images to the buffer and remove old ones if needed\n",
    "        self.examples = list(inp_imgs.to(torch.device(\"cpu\")).chunk(self.sample_size, dim=0)) + self.examples\n",
    "        self.examples = self.examples[:self.max_len]\n",
    "        return inp_imgs\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_samples(model, inp_imgs, steps=60, step_size=10, return_img_per_step=False):\n",
    "        \"\"\"\n",
    "        Function for sampling images for a given model. \n",
    "        Inputs:\n",
    "            model - Neural network to use for modeling E_theta\n",
    "            inp_imgs - Images to start from for sampling. If you want to generate new images, enter noise between -1 and 1.\n",
    "            steps - Number of iterations in the MCMC algorithm.\n",
    "            step_size - Learning rate nu in the algorithm above\n",
    "            return_img_per_step - If True, we return the sample at every iteration of the MCMC\n",
    "        \"\"\"\n",
    "        # Before MCMC: set model parameters to \"required_grad=False\"\n",
    "        # because we are only interested in the gradients of the input. \n",
    "        is_training = model.training\n",
    "        model.eval()\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        inp_imgs.requires_grad = True\n",
    "        \n",
    "        # Enable gradient calculation if not already the case\n",
    "        had_gradients_enabled = torch.is_grad_enabled()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "        # We use a buffer tensor in which we generate noise each loop iteration.\n",
    "        # More efficient than creating a new tensor every iteration.\n",
    "        noise = torch.randn(inp_imgs.shape, device=inp_imgs.device)\n",
    "        \n",
    "        # List for storing generations at each step (for later analysis)\n",
    "        imgs_per_step = []\n",
    "        \n",
    "        # Loop over K (steps)\n",
    "        for _ in range(steps):\n",
    "            # Part 1: Add noise to the input.\n",
    "            noise.normal_(0, 0.005)\n",
    "            inp_imgs.data.add_(noise.data)\n",
    "            inp_imgs.data.clamp_(min=-1.0, max=1.0)\n",
    "            \n",
    "            # Part 2: calculate gradients for the current input.\n",
    "            out_imgs = -model(inp_imgs)\n",
    "            out_imgs.sum().backward()\n",
    "            inp_imgs.grad.data.clamp_(-0.03, 0.03) # For stabilizing and preventing too high gradients\n",
    "\n",
    "            # Apply gradients to our current samples\n",
    "            inp_imgs.data.add_(-step_size * inp_imgs.grad.data)\n",
    "            inp_imgs.grad.detach_()\n",
    "            inp_imgs.grad.zero_()\n",
    "            inp_imgs.data.clamp_(min=-1.0, max=1.0)\n",
    "            \n",
    "            if return_img_per_step:\n",
    "                imgs_per_step.append(inp_imgs.clone().detach())\n",
    "        \n",
    "        # Reactivate gradients for parameters for training\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        model.train(is_training)\n",
    "        \n",
    "        # Reset gradient calculation to setting before this function\n",
    "        torch.set_grad_enabled(had_gradients_enabled)\n",
    "\n",
    "        if return_img_per_step:\n",
    "            return torch.stack(imgs_per_step, dim=0)\n",
    "        else:\n",
    "            return inp_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3f8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_model = CNNModel()\n",
    "sampler = Sampler(energy_model, X_train.shape[1:], 64)\n",
    "opt = optim.Adam(energy_model.parameters(), lr=1e-4, betas=(0, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58cfedbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0020962057169526815, 6.669075901299948e-06, 0.0020895367488265038: 100%|██████████| 4/4 [34:29<00:00, 517.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "N_EPOCHS = 4\n",
    "\n",
    "\n",
    "for i in (pbar := tqdm(range(N_EPOCHS))):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        real_imgs = data\n",
    "        small_noise = torch.randn_like(real_imgs) * 0.005\n",
    "        real_imgs.add_(small_noise).clamp_(min=-1.0, max=1.0)\n",
    "        \n",
    "        # Obtain samples\n",
    "        sampled_imgs = sampler.sample_new_exmps(steps=60, step_size=10)\n",
    "        \n",
    "        # Predict energy score for all images\n",
    "        inp_imgs = torch.cat([real_imgs, sampled_imgs], dim=0)\n",
    "        real_out, sampled_out = energy_model(inp_imgs).chunk(2, dim=0)\n",
    "        \n",
    "        # Calculate losses\n",
    "        reg_loss = 0.1 * ((real_out ** 2).mean() + (sampled_out ** 2).mean())\n",
    "        cdiv_loss = sampled_out.mean() - real_out.mean()\n",
    "        loss = reg_loss + cdiv_loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    pbar.set_description(f'{loss.detach().cpu().item():=}, {reg_loss.detach().cpu().item():=}, {cdiv_loss.detach().cpu().item():=}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5e67cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x108505390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_model.eval()\n",
    "start_imgs = torch.rand((10, ) + data.shape[1:])\n",
    "start_imgs = start_imgs * 2 - 1\n",
    "torch.set_grad_enabled(True)  # Tracking gradients for sampling necessary\n",
    "imgs_per_step = Sampler.generate_samples(energy_model, start_imgs, steps=200, step_size=10, return_img_per_step=True)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd1af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 10, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_per_step.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae591bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14de09f30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_per_step[-1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c322b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
