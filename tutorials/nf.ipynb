{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec62bbc-7f2f-4fa3-8cd4-d7c4fcc3a03f",
   "metadata": {
    "executionInfo": {
     "elapsed": 13278,
     "status": "ok",
     "timestamp": 1734360994785,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "2ec62bbc-7f2f-4fa3-8cd4-d7c4fcc3a03f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import math\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fe81d",
   "metadata": {
    "id": "862fe81d"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14629b28",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734360994786,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "14629b28"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37da032-e817-4841-a30b-741c4b197933",
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1734360995035,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "b37da032-e817-4841-a30b-741c4b197933"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[y_train == 1]\n",
    "\n",
    "X_train = torch.Tensor(X_train).to(torch.int32).unsqueeze(1)\n",
    "X_test = torch.Tensor(X_test).to(torch.int32).unsqueeze(1)\n",
    "\n",
    "train_loader = DataLoader(X_train, batch_size=256, shuffle=False)\n",
    "val_loader = DataLoader(X_test, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f8ad57",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1734360995036,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "94f8ad57"
   },
   "outputs": [],
   "source": [
    "class ImageFlow(nn.Module):\n",
    "    def __init__(self, flows):\n",
    "        super().__init__()\n",
    "        self.flows = nn.ModuleList(flows)\n",
    "        self.prior = torch.distributions.normal.Normal(loc=0, scale=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._get_likelihood(x)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # Given a batch of images, return the latent representation z and ldj of the transformations\n",
    "        z, ldj = x, torch.zeros(x.shape[0], device=device)\n",
    "        for flow in self.flows:\n",
    "            z, ldj = flow(z, ldj, reverse=False)\n",
    "        return z, ldj\n",
    "\n",
    "    def _get_likelihood(self, x, return_ll=False):\n",
    "        z, ldj = self.encode(x)\n",
    "        log_pz = self.prior.log_prob(z).sum(dim=[1,2,3])\n",
    "        log_px = ldj + log_pz\n",
    "        nll = -log_px\n",
    "        # Calculating bits per dimension\n",
    "        bpd = nll * np.log2(np.exp(1)) / np.prod(x.shape[1:])\n",
    "        return bpd.mean() if not return_ll else log_px\n",
    "\n",
    "    def sample(self, shape, z_init=None):\n",
    "        if z_init is None:\n",
    "            z = self.prior.sample(sample_shape=shape).to(device)\n",
    "        else:\n",
    "            z = z_init.to(device)\n",
    "\n",
    "        ldj = torch.zeros(shape[0], device=device)\n",
    "        for flow in reversed(self.flows):\n",
    "            z, ldj = flow(z, ldj, reverse=True)\n",
    "        return z\n",
    "\n",
    "\n",
    "class Dequantization(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=1e-5, quants=256):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.quants = quants\n",
    "\n",
    "    def forward(self, z, ldj, reverse=False):\n",
    "        if not reverse:\n",
    "            z, ldj = self.dequant(z, ldj)\n",
    "            z, ldj = self.sigmoid(z, ldj, reverse=True)\n",
    "        else:\n",
    "            z, ldj = self.sigmoid(z, ldj, reverse=False)\n",
    "            z = z * self.quants\n",
    "            ldj += np.log(self.quants) * np.prod(z.shape[1:])\n",
    "            z = torch.floor(z).clamp(min=0, max=self.quants-1).to(torch.int32)\n",
    "        return z, ldj\n",
    "\n",
    "    def sigmoid(self, z, ldj, reverse=False):\n",
    "        # Applies an invertible sigmoid transformation\n",
    "        if not reverse:\n",
    "            ldj += (-z-2*F.softplus(-z)).sum(dim=[1,2,3])\n",
    "            z = torch.sigmoid(z)\n",
    "            # Reversing scaling for numerical stability\n",
    "            ldj -= np.log(1 - self.alpha) * np.prod(z.shape[1:])\n",
    "            z = (z - 0.5 * self.alpha) / (1 - self.alpha)\n",
    "        else:\n",
    "            z = z * (1 - self.alpha) + 0.5 * self.alpha  # Scale to prevent boundaries 0 and 1\n",
    "            ldj += np.log(1 - self.alpha) * np.prod(z.shape[1:])\n",
    "            ldj += (-torch.log(z) - torch.log(1-z)).sum(dim=[1,2,3])\n",
    "            z = torch.log(z) - torch.log(1-z)\n",
    "        return z, ldj\n",
    "\n",
    "    def dequant(self, z, ldj):\n",
    "        # Transform discrete values to continuous volumes\n",
    "        z = z.to(torch.float32)\n",
    "        z = z + torch.rand_like(z).detach()\n",
    "        z = z / self.quants\n",
    "        ldj -= np.log(self.quants) * np.prod(z.shape[1:])\n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3417e79",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734360995036,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "e3417e79"
   },
   "outputs": [],
   "source": [
    "class VariationalDequantization(Dequantization):\n",
    "\n",
    "    def __init__(self, var_flows, alpha=1e-5):\n",
    "\n",
    "        super().__init__(alpha=alpha)\n",
    "        self.flows = nn.ModuleList(var_flows)\n",
    "\n",
    "    def dequant(self, z, ldj):\n",
    "        z = z.to(torch.float32)\n",
    "        img = (z / 255.0) * 2 - 1\n",
    "\n",
    "        deq_noise = torch.rand_like(z).detach()\n",
    "        deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=True)\n",
    "        for flow in self.flows:\n",
    "            deq_noise, ldj = flow(deq_noise, ldj, reverse=False, orig_img=img)\n",
    "        deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=False)\n",
    "\n",
    "        z = (z + deq_noise) / 256.0\n",
    "        ldj -= np.log(256.0) * np.prod(z.shape[1:])\n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4cb8ce3",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734360995036,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "f4cb8ce3"
   },
   "outputs": [],
   "source": [
    "class CouplingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, network, mask, c_in):\n",
    "        \"\"\"\n",
    "        Coupling layer inside a normalizing flow.\n",
    "        Inputs:\n",
    "            network - A PyTorch nn.Module constituting the deep neural network for mu and sigma.\n",
    "                      Output shape should be twice the channel size as the input.\n",
    "            mask - Binary mask (0 or 1) where 0 denotes that the element should be transformed,\n",
    "                   while 1 means the latent will be used as input to the NN.\n",
    "            c_in - Number of input channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.scaling_factor = nn.Parameter(torch.zeros(c_in))\n",
    "        # Register mask as buffer as it is a tensor which is not a parameter,\n",
    "        # but should be part of the modules state.\n",
    "        self.register_buffer('mask', mask)\n",
    "\n",
    "    def forward(self, z, ldj, reverse=False, orig_img=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            z - Latent input to the flow\n",
    "            ldj - The current ldj of the previous flows.\n",
    "                  The ldj of this layer will be added to this tensor.\n",
    "            reverse - If True, we apply the inverse of the layer.\n",
    "            orig_img (optional) - Only needed in VarDeq. Allows external\n",
    "                                  input to condition the flow on (e.g. original image)\n",
    "        \"\"\"\n",
    "        # Apply network to masked input\n",
    "        z_in = z * self.mask\n",
    "        if orig_img is None:\n",
    "            nn_out = self.network(z_in)\n",
    "        else:\n",
    "            nn_out = self.network(torch.cat([z_in, orig_img], dim=1))\n",
    "        s, t = nn_out.chunk(2, dim=1)\n",
    "\n",
    "        # Stabilize scaling output\n",
    "        s_fac = self.scaling_factor.exp().view(1, -1, 1, 1)\n",
    "        s = torch.tanh(s / s_fac) * s_fac\n",
    "\n",
    "        # Mask outputs (only transform the second part)\n",
    "        s = s * (1 - self.mask)\n",
    "        t = t * (1 - self.mask)\n",
    "\n",
    "        # Affine transformation\n",
    "        if not reverse:\n",
    "            # Whether we first shift and then scale, or the other way round,\n",
    "            # is a design choice, and usually does not have a big impact\n",
    "            z = (z + t) * torch.exp(s)\n",
    "            ldj += s.sum(dim=[1,2,3])\n",
    "        else:\n",
    "            z = (z * torch.exp(-s)) - t\n",
    "            ldj -= s.sum(dim=[1,2,3])\n",
    "\n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c8ef34",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734360995036,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "73c8ef34"
   },
   "outputs": [],
   "source": [
    "def create_checkerboard_mask(h, w, invert=False):\n",
    "    x, y = torch.arange(h, dtype=torch.int32), torch.arange(w, dtype=torch.int32)\n",
    "    xx, yy = torch.meshgrid(x, y, indexing='ij')\n",
    "    mask = torch.fmod(xx + yy, 2)\n",
    "    mask = mask.to(torch.float32).view(1, 1, h, w)\n",
    "    if invert:\n",
    "        mask = 1 - mask\n",
    "    return mask\n",
    "\n",
    "def create_channel_mask(c_in, invert=False):\n",
    "    mask = torch.cat([torch.ones(c_in//2, dtype=torch.float32),\n",
    "                      torch.zeros(c_in-c_in//2, dtype=torch.float32)])\n",
    "    mask = mask.view(1, c_in, 1, 1)\n",
    "    if invert:\n",
    "        mask = 1 - mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360c8aab",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734360995036,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "360c8aab"
   },
   "outputs": [],
   "source": [
    "class ConcatELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Activation function that applies ELU in both direction (inverted and plain).\n",
    "    Allows non-linearity while providing strong gradients for any input (important for final convolution)\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([F.elu(x), F.elu(-x)], dim=1)\n",
    "\n",
    "\n",
    "class LayerNormChannels(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, eps=1e-5):\n",
    "        \"\"\"\n",
    "        This module applies layer norm across channels in an image.\n",
    "        Inputs:\n",
    "            c_in - Number of channels of the input\n",
    "            eps - Small constant to stabilize std\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(1, c_in, 1, 1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, c_in, 1, 1))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=1, keepdim=True)\n",
    "        var = x.var(dim=1, unbiased=False, keepdim=True)\n",
    "        y = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        y = y * self.gamma + self.beta\n",
    "        return y\n",
    "\n",
    "\n",
    "class GatedConv(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_hidden):\n",
    "        \"\"\"\n",
    "        This module applies a two-layer convolutional ResNet block with input gate\n",
    "        Inputs:\n",
    "            c_in - Number of channels of the input\n",
    "            c_hidden - Number of hidden dimensions we want to model (usually similar to c_in)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            ConcatELU(),\n",
    "            nn.Conv2d(2*c_in, c_hidden, kernel_size=3, padding=1),\n",
    "            ConcatELU(),\n",
    "            nn.Conv2d(2*c_hidden, 2*c_in, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        val, gate = out.chunk(2, dim=1)\n",
    "        return x + val * torch.sigmoid(gate)\n",
    "\n",
    "\n",
    "class GatedConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_hidden=32, c_out=-1, num_layers=3):\n",
    "        \"\"\"\n",
    "        Module that summarizes the previous blocks to a full convolutional neural network.\n",
    "        Inputs:\n",
    "            c_in - Number of input channels\n",
    "            c_hidden - Number of hidden dimensions to use within the network\n",
    "            c_out - Number of output channels. If -1, 2 times the input channels are used (affine coupling)\n",
    "            num_layers - Number of gated ResNet blocks to apply\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        c_out = c_out if c_out > 0 else 2 * c_in\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(c_in, c_hidden, kernel_size=3, padding=1)]\n",
    "        for layer_index in range(num_layers):\n",
    "            layers += [GatedConv(c_hidden, c_hidden),\n",
    "                       LayerNormChannels(c_hidden)]\n",
    "        layers += [ConcatELU(),\n",
    "                   nn.Conv2d(2*c_hidden, c_out, kernel_size=3, padding=1)]\n",
    "        self.nn = nn.Sequential(*layers)\n",
    "\n",
    "        self.nn[-1].weight.data.zero_()\n",
    "        self.nn[-1].bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81023a5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1734360995509,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "81023a5d",
    "outputId": "9cc683f4-1866-4ccd-dcee-5377d1f56b3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageFlow(\n",
       "  (flows): ModuleList(\n",
       "    (0): Dequantization()\n",
       "    (1-8): 8 x CouplingLayer(\n",
       "      (network): GatedConvNet(\n",
       "        (nn): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GatedConv(\n",
       "            (net): Sequential(\n",
       "              (0): ConcatELU()\n",
       "              (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): ConcatELU()\n",
       "              (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): LayerNormChannels()\n",
       "          (3): GatedConv(\n",
       "            (net): Sequential(\n",
       "              (0): ConcatELU()\n",
       "              (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): ConcatELU()\n",
       "              (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (4): LayerNormChannels()\n",
       "          (5): GatedConv(\n",
       "            (net): Sequential(\n",
       "              (0): ConcatELU()\n",
       "              (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): ConcatELU()\n",
       "              (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (6): LayerNormChannels()\n",
       "          (7): ConcatELU()\n",
       "          (8): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_simple_flow(use_vardeq=True):\n",
    "    flow_layers = []\n",
    "    if use_vardeq:\n",
    "        vardeq_layers = [CouplingLayer(network=GatedConvNet(c_in=2, c_out=2, c_hidden=16),\n",
    "                                       mask=create_checkerboard_mask(h=28, w=28, invert=(i%2==1)),\n",
    "                                       c_in=1) for i in range(4)]\n",
    "        flow_layers += [VariationalDequantization(var_flows=vardeq_layers)]\n",
    "    else:\n",
    "        flow_layers += [Dequantization()]\n",
    "\n",
    "    for i in range(8):\n",
    "        flow_layers += [CouplingLayer(network=GatedConvNet(c_in=1, c_hidden=32),\n",
    "                                      mask=create_checkerboard_mask(h=28, w=28, invert=(i%2==1)),\n",
    "                                      c_in=1)]\n",
    "\n",
    "    flow_model = ImageFlow(flow_layers).to(device)\n",
    "    return flow_model\n",
    "\n",
    "flow = create_simple_flow(False).to(device).to(device)\n",
    "flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "WsNkVo_F457w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1734360995509,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "WsNkVo_F457w",
    "outputId": "9c8ac054-4ded-43ca-d44c-566dbc97fffb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([np.prod(p.shape) for p in flow.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "410e02b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 531429,
     "status": "ok",
     "timestamp": 1734361526930,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "410e02b3",
    "outputId": "b5c9db28-107f-4222-eb1d-8582971b262d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.902715265750885, val_loss=1.5421753158212606:  30%|███       | 30/100 [08:51<20:39, 17.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "N_EPOCHS = 100\n",
    "opt = optim.Adam(flow.parameters())\n",
    "\n",
    "val_loss = 1_000\n",
    "val_loss_list = [val_loss]\n",
    "best_model = None\n",
    "\n",
    "for i in (pbar := tqdm(range(N_EPOCHS))):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        opt.zero_grad()\n",
    "        loss = flow(data.to(device))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # Validation part\n",
    "    if i % 5 == 0:\n",
    "      with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader):\n",
    "          val_loss += flow(data.to(device)).cpu().item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        if val_loss > sum(val_loss_list[-2:]) / 2:\n",
    "          break\n",
    "      best_model = deepcopy(flow).cpu()\n",
    "\n",
    "    pbar.set_description(f'{loss.detach().cpu().item():=}, {val_loss=}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nLK9YnDZ2Qq-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1734361941558,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "nLK9YnDZ2Qq-",
    "outputId": "ee669e6a-edcd-4872-9758-f7012c9563a4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_imgs(imgs, title=None, row_size=4):\n",
    "    # Form a grid of pictures (we use max. 8 columns)\n",
    "    num_imgs = imgs.shape[0] if isinstance(imgs, torch.Tensor) else len(imgs)\n",
    "    is_int = imgs.dtype==torch.int32 if isinstance(imgs, torch.Tensor) else imgs[0].dtype==torch.int32\n",
    "    nrow = min(num_imgs, row_size)\n",
    "    ncol = int(math.ceil(num_imgs/nrow))\n",
    "    imgs = torchvision.utils.make_grid(imgs, nrow=nrow, pad_value=128 if is_int else 0.5)\n",
    "    np_imgs = imgs.cpu().numpy()\n",
    "    # Plot the grid\n",
    "    plt.figure(figsize=(1.5*nrow, 1.5*ncol))\n",
    "    plt.imshow(np.transpose(np_imgs, (1,2,0)), interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "samples = best_model.to(device).sample([16,1,28,28])\n",
    "show_imgs(samples.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "S_Hoyvlr4NCS",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734361527184,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "S_Hoyvlr4NCS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "CZMhiYIp43nT",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1734361527185,
     "user": {
      "displayName": "Gleb Goncharov",
      "userId": "16359007938490323921"
     },
     "user_tz": -180
    },
    "id": "CZMhiYIp43nT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
